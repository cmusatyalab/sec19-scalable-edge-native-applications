from __future__ import absolute_import, division, print_function

import importlib
import logging
import math
import pickle
import select
import subprocess

import fire
import logzero
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import scipy.interpolate
from logzero import logger
from mpl_toolkits.mplot3d import Axes3D

from rmexp import app_utility_func, schema

logzero.loglevel(logging.DEBUG)


class Profiler(object):
    """A profiler that runs the CV processing of an application.

    The profiling process is performed inside a container.
    Container resource constraints include cpus and memories.
    Outputs are processing latencies, which are stored into the DB.
    """

    def __init__(self, app, cpus, mems, relative_video_uri, trace, profile_exp_name):
        super(Profiler, self).__init__()
        self.app = app
        self.cpus = cpus
        self.mems = mems
        self.relative_video_uri = relative_video_uri
        self.trace = trace
        self.profile_exp_name = profile_exp_name
        assert(type(self.cpus) is list)
        assert(type(self.mems) is list)
        assert(self.profile_exp_name is not None)

    def _issue_cmd(self, cmd_list):
        p = subprocess.Popen(
            cmd_list, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)
        while True:
            [readables, _, _] = select.select(
                [p.stdout, p.stderr], [], [], 1)
            for readable in readables:
                if readable == p.stdout:
                    logger.debug(readable.readline()[:-1])
                elif readable == p.stderr:
                    logger.error(readable.readline()[:-1])
            if p.poll() is not None:
                break

        logger.info('return code: {}'.format(p.returncode))

    def _get_docker_cmd(self, cpu, mem, relative_video_uri, trace, app, omp_num_threads, profile_exp_name):
        # automatically calculate number of workers
        worker_num = int(math.ceil(cpu / float(omp_num_threads)))
        logger.info("Profiling dockers are limited to cgroup profile!!")
        docker_cmd = 'docker run --rm --cgroup-parent=profile --cpus={} --memory={}g -v /home/junjuew/work/resource-management/data:/root/data:ro res /bin/bash -i -c'.format(
            cpu, mem).split()
        docker_cmd.append(
            '". .envrc; OMP_NUM_THREADS={} python rmexp/worker.py batch-process --experiment-name {} --video-uri /root/data/{} --app {} --store-profile True --trace {} --cpu {} --memory {}"'.format(
                omp_num_threads, profile_exp_name, relative_video_uri, app, trace, cpu, mem
            ))
        return docker_cmd

    def profile(self):
        app_module = importlib.import_module(self.app)
        for cpu in self.cpus:
            for mem in self.mems:
                docker_cmd = self._get_docker_cmd(
                    cpu, mem, self.relative_video_uri,
                    self.trace, self.app, app_module.OMP_NUM_THREADS,
                    self.profile_exp_name
                )
                logger.debug('issuing:\n{}'.format(' '.join(docker_cmd)))
                self._issue_cmd(' '.join(docker_cmd))


class ProfileFuncFitter(object):
    """A function fitter that fits profiling data into a function.

    This fitter takes profiling data generated by Profiler from the DB
    and fit a function F: (cpu, mem) --> utility.
    """

    def __init__(self, app, exp_name, l2u_func=None):
        """
        exp_name: profiling experiment name.
        """
        self.app = app
        self.exp_name = exp_name
        # latency to utility function
        # provided by devs based on inherent application latency requirements.
        self.l2u_func = l2u_func if l2u_func is not None else app_utility_func.func_dict[app]
        self._df = self._get_df_by_latency()
        self.func = None

    def _get_df_by_latency(self):
        """Get dataframe by converting latency to utility frame by frame"""
        df = pd.read_sql(
            'select latency, cpu, memory, num_worker from ResourceLatency ' +
            'where name=%(exp_name)s and trace like %(app)s',
            schema.engine,
            params={'app': self.app + '%',  # fuzzy match
                    'exp_name': self.exp_name}
        )
        df['util'] = df['num_worker'] * (df['latency'].apply(self.l2u_func))
        return df

    def print_profile(self):
        print(self._df)

    def plot_cpu(self, plt, memory=2, fmt='o'):
        """Plot cpu vs mean_latency at 2GB memory."""
        plt.plot('cpu',
                 'mean_latency',
                 fmt,
                 data=self._df[self._df['memory'] == 2],
                 label=self.app)

    def smooth_to_non_decreasing(self, cpus, mems, utils, max_cpu, max_mem):
        """This smoothing function eliminates the irregularities in profiling data.

        It smooth a set of 2D points to be monotocally increasing.
        In other word, it outputs a function whose utility remains non-decreasing
        as cpu and memory increase.

        max_cpu, max_mem: maximum cpu and memory that can be 
        passed into the interplolated functions.
        """
        vals = {}
        for idx, _ in enumerate(cpus):
            vals[(cpus[idx], mems[idx])] = utils[idx]
        cpus_sorted = sorted(list(set(cpus)))
        mems_sorted = sorted(list(set(mems)))
        result = []
        for cidx, cpu in enumerate(cpus_sorted):
            for midx, mem in enumerate(mems_sorted):
                candidates = set([(cpu, mem), (cpus_sorted[cidx - 1], mem),
                                  (cpu, mems_sorted[midx - 1]),
                                  (cpus_sorted[cidx - 1], mems_sorted[midx - 1])])
                exception = set()
                if cidx == 0:
                    exception.add((cpus_sorted[cidx - 1], mem))
                    exception.add((cpus_sorted[cidx - 1], mems_sorted[midx - 1]))
                if midx == 0:
                    exception.add((cpu, mems_sorted[midx - 1]))
                candidate_vals = map(lambda x: vals[x] if x in vals else 0,
                                     (candidates - exception))
                non_decreasing_val = max(candidate_vals)

                # if (cpu, mem) in vals:
                result.append((cpu, mem, non_decreasing_val))
                vals[(cpu, mem)] = non_decreasing_val

        max_cpu_ceil = int(math.floor(max(cpus) + 1))
        max_mem_ceil = int(math.floor(max(mems) + 1))
        # add in extra cpu
        for extra_cpu in range(max_cpu_ceil, max_cpu):
            for mem in mems_sorted:
                result.append((extra_cpu, mem, vals[(max(cpus), mem)]))

        # add in extra mem
        for extra_mem in range(max_mem_ceil + 1, max_mem):
            for cpu in cpus_sorted:
                result.append((cpu, extra_mem, vals[(cpu, max(mems))]))

        # add in region where both cpu and mem are extra
        for extra_cpu in range(max_cpu_ceil, max_cpu):
            for extra_mem in range(max_mem_ceil, max_mem):
                result.append((extra_cpu, extra_mem, vals[(max(cpus), max(mems))]))
        return zip(*result)

    def fit_and_plot_profile(self):
        """Interpolate and plot the fitted function (F: <cpu, mem> --> util) in 3D.
        """
        groups = self._df.groupby(['cpu', 'memory'])
        cpus = np.array([name[0] for name, _ in groups])
        mems = np.array([name[1] for name, _ in groups])
        print('calculating per second util by each_util * avg_fps')
        util_avgs = np.array([group['util'].mean() * (
            1000. / group['latency'].mean()) for _, group in groups])

        fig = plt.figure()
        ax = plt.axes(projection='3d')
        ax.scatter(cpus, mems, util_avgs, c='k')
        ax.set_xlabel('CPUs', fontsize=18)
        ax.set_ylabel('Memory', fontsize=18)
        ax.set_zlabel('Avg Utility', fontsize=18)
        for (x, y, z) in zip(cpus, mems, util_avgs):
            pt_txt = '{}'.format((round(x, 2), round(y, 2), round(z, 2)))
        print('{} Profile'.format(self.app))

        cpus, mems, util_avgs = self.smooth_to_non_decreasing(cpus,
                                                              mems,
                                                              util_avgs,
                                                              max_cpu=20,
                                                              max_mem=20)
        cpus, mems, util_avgs = map(list, [cpus, mems, util_avgs])

        # interpolation fitting
        # manually add boundary conditions to avoid out-of-boundary NAN
        # (0,0); (0,1000); (1000, 0) -> 0; (1000, 1000) -> max(util)
        # list operations
        cpu_set, mem_set = set(cpus), set(mems)
        cpus = cpus + [0.] * len(mem_set) + sorted(cpu_set)
        mems = mems + sorted(mem_set) + [0.] * len(cpu_set)
        util_avgs = util_avgs + [0.] * (len(cpu_set) + len(mem_set))

        # interpolate
        cpus, mems, util_avgs = map(np.array, [cpus, mems, util_avgs])
        interpolated_func = scipy.interpolate.LinearNDInterpolator(
            zip(cpus, mems), util_avgs, fill_value=0.)

        xp = np.linspace(0., 10., 40)
        yp = np.linspace(0., 8., 40)
        xx, yy = np.meshgrid(xp, yp)
        zz = interpolated_func(xx, yy)
        ax.set_xlim(10, 0.)
        ax.set_ylim(0, 8.)

        self.func = interpolated_func
        ax.plot_surface(xx, yy, zz, cmap='viridis', edgecolor='none')
        plt.savefig('fig-app-profile-{}.pdf'.format(self.app), bbox_inches='tight')

    def save_func(self):
        """Save application profile as a function"""
        pickle.dump(self.func, open("profile/{}-{}.pkl".format(self.exp_name, self.app), "wb"), -1)

    def plot_latency(self):
        groups = self._df.groupby(['cpu', 'memory'])
        cpus = np.array([name[0] for name, _ in groups])
        mems = np.array([name[1] for name, _ in groups])
        mean_latency = np.array([group['latency'].mean() for _, group in groups])

        fig = plt.figure()
        ax = plt.axes(projection='3d')
        ax.scatter(cpus, mems, mean_latency, c='k')
        ax.set_xlabel('CPUs', fontsize=18)
        ax.set_ylabel('Memory', fontsize=18)
        ax.set_zlabel('Avg Latency', fontsize=18)

        print('{} Latency'.format(self.app))

        cpus, mems, mean_latency = self.smooth_to_non_decreasing(cpus, mems, -mean_latency, max_cpu=20, max_mem=20)
        cpus, mems, mean_latency = map(np.array, [cpus, mems, mean_latency])
        mean_latency = -mean_latency

        # interpolation fitting
        # manually add boundary conditions to avoid out-of-boundary NAN
        # (0,0); (0,1000); (1000, 0) -> inf; (1000, 1000) -> min(latency)
        interpolated_func = scipy.interpolate.LinearNDInterpolator(
            zip(cpus.tolist() + [0, 0, 1000, 1000], mems.tolist() + [0, 1000, 0, 1000]),
            mean_latency.tolist() + [np.max(mean_latency), np.max(mean_latency), np.max(mean_latency), np.min(mean_latency)])

        xp = np.linspace(0., 4., 20)
        yp = np.linspace(0., 2., 20)
        xx, yy = np.meshgrid(xp, yp)
        zz = interpolated_func(xx, yy)

        self.latency_func = interpolated_func
        ax.plot_surface(xx, yy, zz, cmap='viridis', edgecolor='none')

    def save_latency_func(self):
        pickle.dump(self.latency_func, open("profile/latency-{}-{}.pkl".format(self.exp_name, self.app), "wb"), -1)


def main(app):
    profile_exp_name = 'c001-cg-wall-w1'
    if app == 'lego':
        profiler = Profiler('lego',
                            list(np.arange(1, 5, 1)),
                            list(np.arange(2, 2.5, 0.5)),
                            'lego-trace/1/video.mp4',
                            'lego-tr1-profile',
                            profile_exp_name
                            )
        profiler.profile()
    elif app == 'pingpong':
        profiler = Profiler('pingpong',
                            list(np.arange(1, 5, 1)),
                            list(np.arange(2, 2.5, 0.5)),
                            'pingpong-trace/10/video.mp4',
                            'pingpong-tr10-profile',
                            profile_exp_name
                            )
        profiler.profile()
    elif app == 'pool':
        profiler = Profiler('pool',
                            list(np.arange(1, 5, 1)),
                            list(np.arange(2, 2.5, 0.5)),
                            'pool-trace/1/video.mp4',
                            'pool-tr1-profile',
                            profile_exp_name
                            )
        profiler.profile()
    elif app == 'face':
        profiler = Profiler('face',
                            list(np.arange(1, 5, 1)),
                            list(np.arange(2, 2.5, 0.5)),
                            'face-trace/0/video.mp4',
                            'face-tr0-profile',
                            profile_exp_name)
        profiler.profile()
    elif app == 'ikea':
        profiler = Profiler('ikea',
                            list(np.arange(1, 5, 1)),
                            list(np.arange(0.5, 2.5, 0.5)),
                            'ikea-trace/1/video.mp4',
                            'ikea-tr1-profile',
                            profile_exp_name)
        profiler.profile()


if __name__ == "__main__":
    fire.Fire()
